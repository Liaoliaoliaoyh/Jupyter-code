{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ////////////////////// \n",
    "# 官网教程 输入下面这个网址 能看到超炫的聚类\n",
    "# tensorboard --logdir=G:\\Anaconda3\\My_Jupyter\\projector\\projector\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.stack的使用 https://www.jianshu.com/p/25706575f8d4\n",
    "# x = tf.constant([1, 4])\n",
    "# y = tf.constant([2, 5])\n",
    "# z = tf.constant([3, 6])\n",
    "# import tensorflow as tf\n",
    "# c = tf.stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)\n",
    "# d = tf.stack([x, y, z], axis=1)  # [[1, 2, 3], [4, 5, 6]]\n",
    "# with tf.Session() as sess:\n",
    "#     print(sess.run(c))\n",
    "#     print(sess.run(d))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "第0次大循环，测试集准确率为0.1893\n",
      "第100次大循环，测试集准确率为0.8692\n",
      "第200次大循环，测试集准确率为0.8844\n",
      "第300次大循环，测试集准确率为0.8923\n",
      "第400次大循环，测试集准确率为0.8956\n",
      "第500次大循环，测试集准确率为0.9006\n",
      "第600次大循环，测试集准确率为0.9022\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "# 运行次数\n",
    "max_steps = 1001\n",
    "# 图片数量\n",
    "image_num = 3000\n",
    "# 文件路径\n",
    "DIR = 'G:/Anaconda3/My_Jupyter'\n",
    "# 定义会话\n",
    "sess = tf.Session()\n",
    "# 载入图片\n",
    "# 横向打包 mnist数据集的test测试数据集的images图片 [:image_num]从第0张到第image_num = 3000张 打包存放在embedding里\n",
    "embedding = tf.Variable(tf.stack(mnist.test.images[:image_num]), trainable=False, name = 'embedding')\n",
    "# 参数概要\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean) # 平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev',stddev)             # 标准差\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))    # 最大值\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))    # 最小值\n",
    "        tf.summary.histogram('histogram',var)          # 直方图\n",
    "        \n",
    "# 命名空间\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784],name = 'x-input')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10],name = 'y-input')\n",
    "    \n",
    "# 显示图片\n",
    "with tf.name_scope('input_reshape'):\n",
    "    image_shaped_input = tf.reshape(x, [-1,28,28,1])# 把x这个placeholder转化为新形状 -1与None对应 传入几张图不确定 28×28 黑白图 1dim\n",
    "    tf.summary.image('input',image_shaped_input,10)                                                    # 用这个方法传入10张将新构建的图片\n",
    "    \n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W = tf.Variable(tf.zeros([784, 10]), name = 'W')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b = tf.Variable(tf.zeros([10]), name = 'b')\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope('Wx_plus_b'):\n",
    "        Wx_plus_b = tf.matmul(x,W) + b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(Wx_plus_b)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = Wx_plus_b))\n",
    "    tf.summary.scalar('loss',loss)  # 数据比较多的时候 才需要调用 variable_summaries(var)这个函数 这里 loss只有一个值\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train = tf.train.GradientDescentOptimizer(0.1).minimize(loss) \n",
    "#     train = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 预测 求准确率\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))# 返回Ture False 求出最大的数在的位置看它俩返回的位置一样不\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))    \n",
    "        tf.summary.scalar('accuracy',accuracy)      # 算一下准确率的变化\n",
    "        \n",
    "        \n",
    "        \n",
    "# 产生metadate文件\n",
    "# 在这个路径下 检查有没有这样的文件 如果有 删掉\n",
    "# 用写的方式打开这样的文件 其实就是创建文件\n",
    "# 得到测试集的所有标签 one_hot的最大值所在处就是标签值 保存在labels里\n",
    "# 循环3000次 写入metadate.tsv\n",
    "if tf.gfile.Exists(DIR + '/projector/projector/metadate.tsv'):\n",
    "    tf.gfile.DeleteRecursively(DIR + '/projector/projector/metadate.tsv')\n",
    "    \n",
    "with open(DIR + '/projector/projector/metadate.tsv','w') as f:\n",
    "    labels = sess.run(tf.argmax(mnist.test.labels[:],1))\n",
    "    for i in range(image_num):\n",
    "        f.write(str(labels[i]) + '\\n')\n",
    "\n",
    "\n",
    "# 合并所有的summary 也就是说 合并所有之前监测的东西\n",
    "merged = tf.summary.merge_all()                           # 引起血案的地方 jupyter notebook 每次变量不清理 所以每次merge_all前需要restart\n",
    "\n",
    "# 定义一个writer 把我们要看的graph写入这个路径下\n",
    "# FileWriter 类提供了一种机制，用于在给定目录中创建事件文件并向其添加摘要和事件\n",
    "# 该类 异步更新文件内容  这允许训练程序调用方法直接从训练循环向文件添加数据而不会减慢训练速度\n",
    "projector_writer = tf.summary.FileWriter(DIR + '/projector/projector',sess.graph)\n",
    "\n",
    "# 保存网络模型\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# 定义配置文件 配置项\n",
    "config = projector.ProjectorConfig()       \n",
    "\n",
    "# 把配置项做一些设置\n",
    "embed = config.embeddings.add()\n",
    "                \n",
    "# embedding是打包的载入图片 名字的赋值\n",
    "embed.tensor_name = embedding.name\n",
    "\n",
    "# 给他一个 metadate路径的数据 前面生成的metadate\n",
    "embed.metadata_path = DIR + '/projector/projector/metadate.tsv'\n",
    "\n",
    "# 给他一个那个大图片的路径\n",
    "embed.sprite.image_path = DIR + '/projector/data/mnist_10k_sprite.png'\n",
    "\n",
    "# 把那个大图片按28×28切分     \n",
    "embed.sprite.single_image_dim.extend([28,28])\n",
    "\n",
    "# 把这个graph和配置放入 进入可视化       \n",
    "projector.visualize_embeddings(projector_writer,config)\n",
    "\n",
    "\n",
    "# 训练\n",
    "for i in range(max_steps):\n",
    "    pic_data,pic_tag = mnist.train.next_batch(100)  # 一次训练100张图片 训练1001次\n",
    "    # 固定的写法 就这样配置\n",
    "    run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    # 训练一次 统计一次  merged会有一个返回值 存在summary里\n",
    "    summary,_ =  sess.run([merged,train],feed_dict = {x:pic_data,y:pic_tag},options = run_options,run_metadata = run_metadata)\n",
    "    # 记录参数变化\n",
    "    projector_writer.add_run_metadata(run_metadata,'step%03d' % i)\n",
    "    projector_writer.add_summary(summary,i)\n",
    "    \n",
    "#     writer.add_summary(summary,i)\n",
    "    # 每一次大循环 看一下准确率.\n",
    "    if i % 100 == 0:\n",
    "        accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print('第' + str(i) + '次大循环，测试集准确率为' + str(accuracy_rate))\n",
    "        \n",
    "# 把训练好的模型保存下来 路径\n",
    "# 路径的表达 python 默认 /    哈哈哈哈哈哈哈卡了两三天 问题出在这儿\n",
    "# save_path = saver.save(sess,'.\\projector\\projector\\a_model.ckpt',global_step = max_steps)\n",
    "save_path = saver.save(sess,'./projector/projector/a_model.ckpt',global_step = max_steps)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "projector_writer.close()\n",
    "sess.close()\n",
    "tf.logging.set_verbosity(old_v)\n",
    "                \n",
    "                \n",
    "# # 训练完所有图片 即训练完一个大周期 才会打一个点 一共打51个点\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     writer = tf.summary.FileWriter('logdir',sess.graph)\n",
    "#     for epoch in range(51):                                                                                                # 总共训练21次\n",
    "#         for pic in range(n_batch):                                # 每次训练 是从第n个批次里取1个数据 循环结束 所有批次中的数据被训练一次\n",
    "#             pic_data,pic_tag = mnist.train.next_batch(batch_size)   # 从train集中选取batch_size个训练数据 next_batch(我觉得这是bagging 错)\n",
    "#             summary,_ =  sess.run([merged,train],feed_dict={x:pic_data,y:pic_tag}) # 训练一次 统计一次  merged会有一个返回值 存在summary里\n",
    "#         writer.add_summary(summary,epoch)\n",
    "#     # 每一次大循环 看一下准确率\n",
    "#         if epoch % 5 == 0:\n",
    "#             accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "#             print('第' + str(epoch) + '次大循环，测试集准确率为' + str(accuracy_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
