{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)                                             # 把标签转换为只有0 1的热键形式\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 200\n",
    "n_batch = mnist.train.num_examples//batch_size                                                         # 这句看不懂 一共有多少个批次 整除\n",
    "\n",
    "# 给输入数据预留位置\n",
    "# none表示第一个维度可以是任意的长度\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# 创建无中间层的简单网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "Wx_plus_b = tf.matmul(x,W) + b\n",
    "\n",
    "# 预测值\n",
    "prediction = tf.nn.softmax(Wx_plus_b)                                                 # 信号的总和通过softmax转化为概率值存放在预测变量里\n",
    "\n",
    "# 准备拟合\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))                                             # 二次代价函数 = 样本值 - 预测值 的平方 求平均\n",
    "train = tf.train.GradientDescentOptimizer(0.2).minimize(loss) \n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 定义求准确率的方法 测试一下模型的准确率\n",
    "# 这个y是标签 y的位置是数字答案 这里其实就是用预测值（prediction刚好由softmax得概率）与标签所得答案比较 得到 布尔型列表 \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))    # 返回 Ture False 求出最大的数在的位置 看它俩返回的位置一样不\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))                                        # cast是强制类型转换 然后 求均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次大循环，测试集准确率为0.6712\n",
      "第10次大循环，测试集准确率为0.7551\n",
      "第20次大循环，测试集准确率为0.8362\n",
      "第30次大循环，测试集准确率为0.8601\n",
      "第40次大循环，测试集准确率为0.8709\n",
      "第50次大循环，测试集准确率为0.8777\n",
      "第60次大循环，测试集准确率为0.8814\n",
      "第70次大循环，测试集准确率为0.8844\n",
      "第80次大循环，测试集准确率为0.888\n",
      "第90次大循环，测试集准确率为0.8917\n",
      "第100次大循环，测试集准确率为0.8941\n",
      "第110次大循环，测试集准确率为0.8962\n",
      "第120次大循环，测试集准确率为0.8972\n",
      "第130次大循环，测试集准确率为0.8983\n",
      "第140次大循环，测试集准确率为0.8993\n",
      "第150次大循环，测试集准确率为0.9008\n",
      "第160次大循环，测试集准确率为0.9011\n",
      "第170次大循环，测试集准确率为0.9024\n",
      "第180次大循环，测试集准确率为0.9038\n",
      "第190次大循环，测试集准确率为0.9044\n"
     ]
    }
   ],
   "source": [
    "# 跑起来\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(200):                                                                                              # 总共训练21次\n",
    "        for pic in range(n_batch):                                # 每次训练 是从第n个批次里取1个数据 循环结束 所有批次中的数据被训练一次\n",
    "            pic_data,pic_tag = mnist.train.next_batch(batch_size)   # 从train集中选取batch_size个训练数据 next_batch(我觉得这是bagging 错)\n",
    "            sess.run(train,feed_dict={x:pic_data,y:pic_tag})        # 获取一个训练数据 这儿就训练一次   \n",
    "        # 每一次大循环 看一下准确率\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print('第' + str(epoch) + '次大循环，测试集准确率为' + str(accuracy_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次大循环，测试集准确率为0.8706\n",
      "第10次大循环，测试集准确率为0.9146\n",
      "第20次大循环，测试集准确率为0.9194\n",
      "第30次大循环，测试集准确率为0.9232\n",
      "第40次大循环，测试集准确率为0.9256\n",
      "第50次大循环，测试集准确率为0.926\n",
      "第60次大循环，测试集准确率为0.9272\n",
      "第70次大循环，测试集准确率为0.9279\n",
      "第80次大循环，测试集准确率为0.9287\n",
      "第90次大循环，测试集准确率为0.9292\n",
      "第100次大循环，测试集准确率为0.9291\n",
      "第110次大循环，测试集准确率为0.9291\n",
      "第120次大循环，测试集准确率为0.9298\n",
      "第130次大循环，测试集准确率为0.9298\n",
      "第140次大循环，测试集准确率为0.9298\n",
      "第150次大循环，测试集准确率为0.9305\n",
      "第160次大循环，测试集准确率为0.9307\n",
      "第170次大循环，测试集准确率为0.9301\n",
      "第180次大循环，测试集准确率为0.9308\n",
      "第190次大循环，测试集准确率为0.9308\n"
     ]
    }
   ],
   "source": [
    "# https://www.cnblogs.com/nxf-rabbit75/p/10639833.html\n",
    "# 如果你是使用 GPU 版 TensorFlow 的话,并且你想在显卡高占用率的情况下训练模型\n",
    "# 那你要注意在初始化 Session 的时候为其分配固定数量的显存,否则可能会在开始训练的时候直接报错退出: \n",
    "# 这时你需要用下面的方法创建 Session: \n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)  #fraction设置使用内存的百分比。\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(200):                                                                                              # 总共训练21次\n",
    "        for pic in range(n_batch):                                # 每次训练 是从第n个批次里取1个数据 循环结束 所有批次中的数据被训练一次\n",
    "            pic_data,pic_tag = mnist.train.next_batch(batch_size)   # 从train集中选取batch_size个训练数据 next_batch(我觉得这是bagging 错)\n",
    "            sess.run(train,feed_dict={x:pic_data,y:pic_tag})        # 获取一个训练数据 这儿就训练一次   \n",
    "        # 每一次大循环 看一下准确率\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print('第' + str(epoch) + '次大循环，测试集准确率为' + str(accuracy_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在开启对话session前，先创建一个 tf.ConfigProto() 实例对象\n",
    "# 通过 allow_soft_placement 参数自动将无法放在 GPU 上的操作放回 CPU\n",
    "gpuConfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "# Case 1\n",
    "# 限定使用显存的比例 一个进程使用 60% 的显存\n",
    "gpuConfig.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "# Case 2\n",
    "# 运行时需要多少再给多少\n",
    "gpuConfig.gpu_options.allow_growth = True\n",
    "# Case 3\n",
    "# 指定可以被看见的GPU设备\n",
    "# 默认情况，TF 会占用所有 GPU 的所有内存, 我们可以指定 只有 GPU0 和 GPU1 这两块卡被看到，从而达到限制其使用所有GPU的目的\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'  \n",
    "\n",
    "# 把你的配置部署到session\n",
    "with tf.Session(config=gpuConfig) as sess:\n",
    "#  pass\n",
    "\n",
    "#这样，如果你指定的卡的显存是8000M的话，你这个进程只能用4800M。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
