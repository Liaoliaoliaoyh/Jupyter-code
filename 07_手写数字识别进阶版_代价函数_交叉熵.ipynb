{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代价函数：任何可以衡量模型预测结果值与其真实值之间差异的函数，如果存在多个样本，代价函数统计结果应该为所有样本的差异之和\n",
    "# 代价函数即模型误差，是反向传播中求梯度的基础，同时也是模型最终达到期望效果的衡量指标\n",
    "\n",
    "# 二次代价函数(均方误差)(线性回归)(神经元线性)\n",
    "# W和b的梯度跟激活函数的梯度成正比，激活函数的梯度越大，W和b的大小调整的越快，训练收敛得就越快\n",
    "\n",
    "# 交叉熵代价函数(逻辑回归)(sigmoid)(神经元S型)\n",
    "# W和b的调整与激活函数的导数无关，只与输出值与实际值的误差有关。误差越大，梯度越大，调整越快，收敛越快\n",
    "\n",
    "# 对数似然代价函数(多分类问题)(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-9d7c679d7216>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-9d7c679d7216>:26: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "第1次，test准确率0.8251\n",
      "第2次，test准确率0.8937\n",
      "第3次，test准确率0.9022\n",
      "第4次，test准确率0.9064\n",
      "第5次，test准确率0.9097\n",
      "第6次，test准确率0.9104\n",
      "第7次，test准确率0.9123\n",
      "第8次，test准确率0.9138\n",
      "第9次，test准确率0.9157\n",
      "第10次，test准确率0.9165\n",
      "第11次，test准确率0.917\n",
      "第12次，test准确率0.9177\n",
      "第13次，test准确率0.9186\n",
      "第14次，test准确率0.9191\n",
      "第15次，test准确率0.92\n",
      "第16次，test准确率0.92\n",
      "第17次，test准确率0.9203\n",
      "第18次，test准确率0.921\n",
      "第19次，test准确率0.9208\n",
      "第20次，test准确率0.9216\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)                                             # 把标签转换为只有0 1的热键形式\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 50\n",
    "n_batch = mnist.train.num_examples//batch_size                                                         # 这句看不懂 一共有多少个批次 整除\n",
    "\n",
    "# 给输入数据预留位置\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# 创建无中间层的简单网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "Wx_plus_b = tf.matmul(x,W) + b\n",
    "\n",
    "# 预测值\n",
    "prediction = tf.nn.softmax(Wx_plus_b)                                                 # 信号的总和通过softmax转化为概率值存放在预测变量里\n",
    "# prediction = tf.nn.sigmoid(Wx_plus_b)\n",
    "\n",
    "# 二次代价函数 换成 交叉熵代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))                                           # 二次代价函数 = 样本值 - 预测值 的平方 求平均\n",
    "# loss = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)                                  # 交叉熵 softmax  标签 预测值\n",
    "\n",
    "# prediction = tf.nn.softmax(Wx_plus_b)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))  # softmax  交叉熵  求均值\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 定义求准确率的方法 测试一下模型的准确率\n",
    "# 这个y是标签 y的位置是数字答案 这里其实就是用预测值（prediction刚好由softmax得概率）与标签所得答案比较 得到 布尔型列表 \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))    # 返回 Ture False 求出最大的数在的位置 看它俩返回的位置一样不\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))                                        # cast是强制类型转换 然后 求均值\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):                                                                                              # 总共训练21次\n",
    "        for pic in range(n_batch):                                # 每次训练 是从第n个批次里取1个数据 循环结束 所有批次中的数据被训练一次\n",
    "            pic_data,pic_tag = mnist.train.next_batch(batch_size)   # 从train集中选取batch_size个训练数据 next_batch(我觉得这是bagging 错)\n",
    "            sess.run(train,feed_dict={x:pic_data,y:pic_tag})        # 获取一个训练数据 这儿就训练一次   \n",
    "        # 每一次大循环 看一下准确率\n",
    "        if epoch % 1 == 0:\n",
    "            accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "            print('第' + str(epoch+1) + '次，test准确率' + str(accuracy_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.sigmoid(Wx_plus_b)                                                       # sigmoid + 交叉熵代价函数\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)\n",
    "\n",
    "第1次，test准确率0.8979\n",
    "第2次，test准确率0.9094\n",
    "第3次，test准确率0.912\n",
    "第4次，test准确率0.9081\n",
    "第5次，test准确率0.909\n",
    "第6次，test准确率0.9116\n",
    "第7次，test准确率0.9111\n",
    "第8次，test准确率0.9134\n",
    "第9次，test准确率0.9144\n",
    "第10次，test准确率0.9125\n",
    "第11次，test准确率0.9122\n",
    "第12次，test准确率0.9141\n",
    "第13次，test准确率0.9115\n",
    "第14次，test准确率0.9114\n",
    "第15次，test准确率0.913\n",
    "第16次，test准确率0.9144\n",
    "第17次，test准确率0.9158\n",
    "第18次，test准确率0.9162\n",
    "第19次，test准确率0.9152\n",
    "第20次，test准确率0.9168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(Wx_plus_b)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)                                  # 交叉熵 softmax  标签 预测值\n",
    "\n",
    "第1次，test准确率0.8462\n",
    "第2次，test准确率0.8476\n",
    "第3次，test准确率0.8547\n",
    "第4次，test准确率0.8525\n",
    "第5次，test准确率0.8547\n",
    "第6次，test准确率0.8582\n",
    "第7次，test准确率0.8544\n",
    "第8次，test准确率0.8565\n",
    "第9次，test准确率0.8556\n",
    "第10次，test准确率0.8543\n",
    "第11次，test准确率0.8573\n",
    "第12次，test准确率0.8564\n",
    "第13次，test准确率0.854\n",
    "第14次，test准确率0.8573\n",
    "第15次，test准确率0.8513\n",
    "第16次，test准确率0.8582\n",
    "第17次，test准确率0.8573\n",
    "第18次，test准确率0.8542\n",
    "第19次，test准确率0.8568\n",
    "第20次，test准确率0.8553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(Wx_plus_b)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=Wx_plus_b))  # softmax  交叉熵  求均值\n",
    "\n",
    "第1次，test准确率0.9102\n",
    "第2次，test准确率0.9165\n",
    "第3次，test准确率0.9184\n",
    "第4次，test准确率0.9201\n",
    "第5次，test准确率0.9211\n",
    "第6次，test准确率0.9219\n",
    "第7次，test准确率0.9215\n",
    "第8次，test准确率0.92\n",
    "第9次，test准确率0.9226\n",
    "第10次，test准确率0.9239\n",
    "第11次，test准确率0.9229\n",
    "第12次，test准确率0.9238\n",
    "第13次，test准确率0.9242\n",
    "第14次，test准确率0.9237\n",
    "第15次，test准确率0.9242\n",
    "第16次，test准确率0.9248\n",
    "第17次，test准确率0.9233\n",
    "第18次，test准确率0.9239\n",
    "第19次，test准确率0.9248\n",
    "第20次，test准确率0.9247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.sigmoid(Wx_plus_b)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=Wx_plus_b))  # softmax  交叉熵  求均值\n",
    "\n",
    "第1次，test准确率0.9084\n",
    "第2次，test准确率0.9172\n",
    "第3次，test准确率0.9201\n",
    "第4次，test准确率0.9221\n",
    "第5次，test准确率0.9216\n",
    "第6次，test准确率0.921\n",
    "第7次，test准确率0.922\n",
    "第8次，test准确率0.9226\n",
    "第9次，test准确率0.921\n",
    "第10次，test准确率0.9215\n",
    "第11次，test准确率0.9241\n",
    "第12次，test准确率0.9242\n",
    "第13次，test准确率0.9238\n",
    "第14次，test准确率0.9243\n",
    "第15次，test准确率0.9223\n",
    "第16次，test准确率0.9231\n",
    "第17次，test准确率0.9244\n",
    "第18次，test准确率0.9248\n",
    "第19次，test准确率0.924\n",
    "第20次，test准确率0.924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.sigmoid(Wx_plus_b)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "\n",
    "第1次，test准确率0.865\n",
    "第2次，test准确率0.8783\n",
    "第3次，test准确率0.8822\n",
    "第4次，test准确率0.8866\n",
    "第5次，test准确率0.8898\n",
    "第6次，test准确率0.8918\n",
    "第7次，test准确率0.8938\n",
    "第8次，test准确率0.896\n",
    "第9次，test准确率0.8961\n",
    "第10次，test准确率0.8978\n",
    "第11次，test准确率0.8992\n",
    "第12次，test准确率0.9004\n",
    "第13次，test准确率0.8993\n",
    "第14次，test准确率0.9013\n",
    "第15次，test准确率0.9021\n",
    "第16次，test准确率0.9014\n",
    "第17次，test准确率0.9029\n",
    "第18次，test准确率0.9025\n",
    "第19次，test准确率0.9036\n",
    "第20次，test准确率0.9024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
