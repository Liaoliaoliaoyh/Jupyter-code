{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各种优化器对比：\n",
    "# 标准梯度下降法：先算所有样本汇总误差，再由总误差更新权值\n",
    "# 随机梯度下降法：随机抽取一个样本计算误差，更新权值\n",
    "# 批量梯度下降法：随机抽取一批样本计算总误差，再由这个batch总误差更新权值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-c62d775eeeb9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\Anaconda3-5.2.0\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-3-c62d775eeeb9>:23: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "第1次，train准确率 0.9070727  test准确率 0.9118\n",
      "第2次，train准确率 0.91712725  test准确率 0.9175\n",
      "第3次，train准确率 0.9214  test准确率 0.9225\n",
      "第4次，train准确率 0.9250364  test准确率 0.925\n",
      "第5次，train准确率 0.9254364  test准确率 0.924\n",
      "第6次，train准确率 0.92694545  test准确率 0.9261\n",
      "第7次，train准确率 0.92938185  test准确率 0.9274\n",
      "第8次，train准确率 0.92938185  test准确率 0.9268\n",
      "第9次，train准确率 0.9309091  test准确率 0.9261\n",
      "第10次，train准确率 0.9306  test准确率 0.9252\n",
      "第11次，train准确率 0.93194544  test准确率 0.928\n",
      "第12次，train准确率 0.9332727  test准确率 0.928\n",
      "第13次，train准确率 0.9326364  test准确率 0.9287\n",
      "第14次，train准确率 0.9329818  test准确率 0.9262\n",
      "第15次，train准确率 0.93283635  test准确率 0.9282\n",
      "第16次，train准确率 0.93252724  test准确率 0.9261\n",
      "第17次，train准确率 0.9346909  test准确率 0.9253\n",
      "第18次，train准确率 0.93430907  test准确率 0.9267\n",
      "第19次，train准确率 0.93398184  test准确率 0.9264\n",
      "第20次，train准确率 0.9339455  test准确率 0.9269\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# 每次训练数据大小 和 批次大小\n",
    "batch_size = 50\n",
    "n_batch = mnist.train.num_examples//batch_size                                                         # 这句看不懂 一共有多少个批次 整除\n",
    "\n",
    "# 给输入数据预留位置\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# 创建网络\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 预测值\n",
    "Wx_plus_b = tf.matmul(x,W) + b\n",
    "\n",
    "# 添加激活函数  softmax 因为是比概率\n",
    "prediction = tf.nn.softmax(Wx_plus_b)\n",
    "\n",
    "# 定义损失函数  交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=Wx_plus_b))\n",
    "\n",
    "# 定义优化器\n",
    "# train = tf.train.GradientDescentOptimizer(0.2).minimize(loss)  # 梯度下降\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(loss) # Adam 快 这个优化器居然需要初始化\n",
    "# train = tf.train.AdadeltaOptimizer    # 不需要设置默认学习率\n",
    "# train = tf.train.AdagradDAOptimizer\n",
    "# train = tf.train.AdagradOptimizer(0.01) # GradientDescentOptimizerd的进步 小学习率学习常见数据 大学习率学习罕见数据 稀疏数据集\n",
    "# train = tf.train.FtrlOptimizer\n",
    "# train = tf.train.MomentumOptimizer(0.9)  # 带加速度的梯度下降\n",
    "# train = tf.train.ProximalAdagradOptimizer\n",
    "# train = tf.train.ProximalGradientDescentOptimizer\n",
    "# train = tf.train.RMSPropOptimizer(0.001)  # AdagradOptimizer的进步 学习率不会越来越低\n",
    "# train = tf.train.SyncReplicasOptimizer\n",
    "\n",
    "\n",
    "# 定义求准确率方法\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "# 训练前初始化所有变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):\n",
    "        for pic in range(n_batch):\n",
    "            pic_data,pic_tag = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train,feed_dict={x:pic_data,y:pic_tag})\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            train_accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels})   # 训练集正确率\n",
    "            test_accuracy_rate = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})      # 测试集正确率\n",
    "            print('第' + str(epoch+1) + '次，train准确率 ' + str(train_accuracy_rate) + '  test准确率 ' + str(test_accuracy_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
